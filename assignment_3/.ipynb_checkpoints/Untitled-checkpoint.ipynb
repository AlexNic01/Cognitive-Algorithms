{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.io as io\n",
    "from scipy.linalg import inv\n",
    "import pdb\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0.5],\n",
       "       [ 0.5,  0.5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.cov(4*np.array([[1,-1],[1,0],[3,0],[3,1]]).T, bias = 1)\n",
    "x = np.array([1,-1,-1,1])\n",
    "y = np.array([1,-1,0,0])\n",
    "np.cov(x,y, bias=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(6)\n",
    "b = np.array([0,2,0,2,0,2])\n",
    "a -= b \n",
    "a[b==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lda_brut(X,Y):\n",
    "    w_p = X[Y==1].mean(axis=0)\n",
    "    w_m = X[Y==-1].mean(axis=0)\n",
    "    n = len(w_p)\n",
    "    S_b = (w_p - w_m).reshape(n,1).dot((w_p - w_m).reshape(n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_lda(X,Y):\n",
    "    ''' Trains a linear discriminant analysis\n",
    "    Definition:  w, b   = train_lda(X,Y)\n",
    "    Input:       X       -  DxN array of N data points with D features\n",
    "                 Y       -  1D array of length N of class labels {-1, 1}\n",
    "    Output:      w       -  1D array of length D, weight vector  \n",
    "                 b       -  bias term for linear classification                          \n",
    "    '''\n",
    "    # your code here \n",
    "    # hint: use the scipy/numpy function sp.cov\n",
    "    w_p = X[Y==1].mean(axis=0)\n",
    "    w_m = X[Y==-1].mean(axis=0)\n",
    "    n = len(w_p)\n",
    "    S_B = (w_p - w_m).reshape(n,1).dot((w_p - w_m).reshape(n,1))\n",
    "    S_W = np.cov(X[Y==1], rowvar = False, bias = 1)\n",
    "    S_W += np.cov(X[Y==-1], rowvar = False, bias = 1)\n",
    "    eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_usps_data(fname, digit=3):\n",
    "    ''' Loads USPS (United State Postal Service) data from <fname> \n",
    "    Definition:  X, Y = load_usps_data(fname, digit = 3)\n",
    "    Input:       fname   - string\n",
    "                 digit   - optional, integer between 0 and 9, default is 3\n",
    "    Output:      X       -  DxN array with N images with D pixels\n",
    "                 Y       -  1D array of length N of class labels\n",
    "                             (1 - picture displays <digit>, -1 - otherwise)                           \n",
    "    '''\n",
    "    # load the data\n",
    "    data = io.loadmat(fname)\n",
    "    # extract images and labels\n",
    "    X = data['data_patterns']\n",
    "    Y = data['data_labels']\n",
    "    Y = Y[digit,:]\n",
    "    return X, Y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "def load_bci_data(fname):\n",
    "    ''' Loads BCI data (one subject, copy-spelling experiment) from <fname> \n",
    "    Definition:  X, Y = load_bci_data(fname)\n",
    "    Input:       fname   - string\n",
    "    Output:      X       -  DxN array with N images with D pixels\n",
    "                 Y       -  1D array of length N of class labels \n",
    "                            (1- target, -1 - non-target)                         \n",
    "    '''\n",
    "    # load the data\n",
    "    data = io.loadmat(fname)\n",
    "    # extract time-electrode features and labels\n",
    "    X = data['X']\n",
    "    Y = data['Y']\n",
    "    # collapse the time-electrode dimensions\n",
    "    X = sp.reshape(X,(X.shape[0]*X.shape[1],X.shape[2]))\n",
    "    # transform the labels to (-1,1)\n",
    "    Y = sp.sign((Y[0,:]>0) -.5)\n",
    "    return X,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_perceptron(X,Y,iterations=200,eta=.1):\n",
    "    ''' Trains a linear perceptron\n",
    "    Definition:  w, b, acc  = train_perceptron(X,Y,iterations=200,eta=.1)\n",
    "    Input:       X       -  DxN array of N data points with D features\n",
    "                 Y       -  1D array of length N of class labels {-1, 1}\n",
    "                 iter    -  optional, number of iterations, default 200\n",
    "                 eta     -  optional, learning rate, default 0.1\n",
    "    Output:      w       -  1D array of length D, weight vector \n",
    "                 b       -  bias term for linear classification                          \n",
    "    '''\n",
    "    #include the bias term by adding a row of ones to X \n",
    "    X = sp.concatenate((sp.ones((1,X.shape[1])), X))\n",
    "    #initialize weight vector\n",
    "    weights = sp.ones((X.shape[0]))/X.shape[0]\n",
    "    for it in sp.arange(iterations):\n",
    "        # indices of misclassified data\n",
    "        wrong = (sp.sign(weights.dot(X)) != Y).nonzero()[0]\n",
    "        if wrong.shape[0] > 0:\n",
    "            # pick a random misclassified data point\n",
    "            m = wrong[sp.random.random_integers(0, wrong.shape[0]-1)]\n",
    "            #update weight vector (use variable learning rate (eta/(1.+it)) )\n",
    "            weights = weights  + (eta/(1.+it)) * X[:, m] * Y[m]; \n",
    "            # compute accuracy\n",
    "            wrong = (sp.sign(weights.dot(X)) != Y).nonzero()[0]\n",
    "    b = -weights[0] \n",
    "    w = weights[1:]\n",
    "    return w,b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_ncc(X,Y):\n",
    "    ''' Trains a nearest centroid classifier\n",
    "    Definition:  w, b   = train_ncc(X,Y)\n",
    "    Input:       X       -  DxN array of N data points with D features\n",
    "                 Y       -  1D array of length N of class labels {-1, 1}\n",
    "    Output:      w       -  1D array of length D, weight vector  \n",
    "                 b       -  bias term for linear classification                          \n",
    "    '''\n",
    "    #class means\n",
    "    mupos = sp.mean(X[:,Y>0],axis=1)\n",
    "    muneg = sp.mean(X[:,Y<0],axis=1)\n",
    "    #weight vector and bias term\n",
    "    w = mupos - muneg\n",
    "    b = (w.dot(mupos) + w.dot(muneg))/2.\n",
    "    return w,b\n",
    "    \t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_histogram(X, Y, w, b, cname):\n",
    "    ''' Plots a histogram of classifier outputs (w^T X) for each class \n",
    "    Input:          X       -  DxN array of N data points with D features\n",
    "                    Y       -  1D array of length N of class labels\n",
    "                    w       -  1D array of length D, weight vector \n",
    "                    b       -  bias term for linear classification  \n",
    "                    cname   - name of the classifier \n",
    "    '''\n",
    "    pl.hist((w.dot(X[:,Y<0]), w.dot(X[:,Y>0])))\n",
    "    pl.xlabel(\"w^T X\")\n",
    "    pl.title(cname + ' ' + str(100*sp.sum(sp.sign(w.dot(X)-b)==Y)/X.shape[1]) + \"%\")   \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_classifiers_toy():\n",
    "    '''\n",
    "    Compares 3 different linear classifiers (Nearest-Centroid, Linear Discriminant Analysis, \n",
    "    Perceptron) on 2 dimensional toy data\n",
    "    '''\n",
    "    #generate 2D data\n",
    "    N =500\n",
    "    cov = sp.array([[5, 0], [0, 0.5]])\n",
    "    x1 = sp.random.multivariate_normal([-0.5, -0.5], cov, N) \n",
    "    x2 = sp.random.multivariate_normal([2.5, 0.5], cov, N) \n",
    "    X = sp.vstack((x1, x2)).transpose()\n",
    "    Y = sp.hstack((sp.ones((N)), -1*sp.ones((N))))\n",
    "    \t\n",
    "    #train NCC, LDA and Perceptron\n",
    "    w_ncc,b_ncc = train_ncc(X,Y)\n",
    "    w_lda,b_lda = train_lda(X,Y)\n",
    "    w_per,b_per = train_perceptron(X,Y)\n",
    "    \t    \n",
    "    #plot result\n",
    "    pl.figure()\n",
    "    b_ncc = 10*b_ncc / sp.linalg.norm(w_ncc)\n",
    "    b_lda = 10*b_lda / sp.linalg.norm(w_lda)\n",
    "    b_per = 10*b_per / sp.linalg.norm(w_per)\n",
    "    w_lda = 10*w_lda / sp.linalg.norm(w_lda)\n",
    "    w_ncc = 10*w_ncc / sp.linalg.norm(w_ncc)\n",
    "    w_per = 10*w_per / sp.linalg.norm(w_per)\n",
    "    pl.plot([-w_lda[1], w_lda[1]], [w_lda[0]+b_lda/w_lda[1], -w_lda[0]+b_lda/w_lda[1]], \n",
    "        color = 'k', label='LDA: Acc ' + str(100*sp.sum(sp.sign(w_lda.dot(X)-b_lda)==Y)/X.shape[1]) + \"%\")\n",
    "    pl.hold(True)\n",
    "    pl.plot([-w_ncc[1], w_ncc[1]], [w_ncc[0]+b_ncc/w_ncc[1], -w_ncc[0]+b_ncc/w_ncc[1]], \n",
    "        color = 'r', linestyle = '--', label='NCC: Acc ' + str(100*sp.sum(sp.sign(w_ncc.dot(X)-b_ncc)==Y)/X.shape[1]) + \"%\")\n",
    "    pl.plot([-w_per[1], w_per[1]], [w_per[0]+b_per/w_per[1], -w_per[0]+b_per/w_per[1]], \n",
    "        color = 'g', linestyle = ':', label='PER: Acc ' + str(100*sp.sum(sp.sign(w_per.dot(X)-b_per)==Y)/X.shape[1]) + \"%\")\n",
    "    pl.plot(x1[:,0], x1[:,1], 'y+')\n",
    "    pl.plot(x2[:,0], x2[:,1], 'b+')\n",
    "    pl.axis('equal')\t\n",
    "    pl.legend(loc=1)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_classifiers(usps = True, digit = 3):\n",
    "    '''\n",
    "    Compares 3 different linear classifiers (Nearest-Centroid, Linear Discriminant Analysis, \n",
    "    Perceptron) on either USPS data (for usps=True) or on BCI data (for usps = False)\n",
    "    '''\n",
    "    if usps: #load usps data set\n",
    "        X,Y = load_usps_data('usps.mat',digit)\n",
    "        tit = 'USPS(' + str(digit) + ')'\n",
    "    else: #load bci data set \n",
    "        X,Y = load_bci_data('bcidata.mat')\n",
    "        tit = 'BCI'\n",
    "    \n",
    "    #Use crossvalidation to estimate the training and test accuracies\n",
    "    acc_cv = sp.zeros((5, 6))\n",
    "    (acc_cv[:,0],acc_cv[:,1]) = crossvalidate(X,Y,trainfun=train_ncc)\n",
    "    (acc_cv[:,2],acc_cv[:,3]) = crossvalidate(X,Y,trainfun=train_lda)\n",
    "    (acc_cv[:,4],acc_cv[:,5]) = crossvalidate(X,Y,trainfun=train_perceptron)\n",
    "        \n",
    "    #Plot the crossvalidation output\n",
    "    pl.figure()\n",
    "    ax1 = pl.subplot2grid((2,3), (0,0), colspan = 3)\n",
    "    pl.bar(sp.array([1, 2, 3, 4, 5, 6]) - 0.4,  acc_cv.mean(0), width = 0.8,\n",
    "        yerr =  acc_cv.std(0), ecolor = 'k', color = 'g')\n",
    "    pl.xticks([1, 2, 3, 4, 5, 6], ['NCC tain', 'NCC test', 'LDA train', 'LDA test', \n",
    "        'PER train', 'PER test'])\n",
    "    pl.xlim([0, 7])\n",
    "    pl.ylim([0.5, 1])\n",
    "    pl.ylabel('CV Accuracy')\n",
    "    pl.title(tit + ' data set')\n",
    "\n",
    "    #Train the classifiers and plot the output histograms\n",
    "    w_ncc,b_ncc = train_ncc(X,Y)\n",
    "    w_lda,b_lda = train_lda(X,Y)\n",
    "    w_per,b_per= train_perceptron(X,Y)\n",
    "    \n",
    "    ax2 = pl.subplot2grid((2,3), (1,0))\n",
    "    plot_histogram(X, Y, w_ncc, b_ncc, 'NCC')\n",
    "    ax3 = pl.subplot2grid((2,3), (1,1))\n",
    "    plot_histogram(X, Y, w_lda, b_lda, 'LDA')\n",
    "    ax4 = pl.subplot2grid((2,3), (1,2))\n",
    "    plot_histogram(X, Y, w_per, b_per, 'PER')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossvalidate(X,Y, f=5, trainfun=train_ncc):\n",
    "\t''' \n",
    "\tTest generalization performance of a linear classifier by crossvalidation\n",
    "\tDefinition:     crossvalidate(X,Y, f=5, trainfun=train_ncc)\n",
    "    Input:      X        -  DxN array of N data points with D features\n",
    "                Y        -  1D array of length N of class labels\n",
    "    \t\t\tf\t     - number of cross-validation folds\n",
    "\t\t\t\ttrainfun - function for linear classification training\n",
    "    Output:     acc_train - (f,) array of accuracies in test train folds\n",
    "                acc_test  - (f,) array of accuracies in each test fold\n",
    "\t'''\n",
    "\tN = f*(X.shape[-1]/f)\n",
    "\tidx = sp.reshape(sp.arange(N),(f,N/f))\n",
    "\tacc_train = sp.zeros((f))\n",
    "\tacc_test = sp.zeros((f))\n",
    "\t\n",
    "\tfor ifold in sp.arange(f):\n",
    "\t\ttestidx = sp.zeros((f),dtype=bool)\n",
    "\t\ttestidx[ifold] = 1\n",
    "\t\ttest = idx[testidx,:].flatten()\n",
    "\t\ttrain = idx[~testidx,:].flatten()\n",
    "\t\tw,b = trainfun(X[:,train],Y[train])\n",
    "\t\tacc_train[ifold] = sp.sum(sp.sign(w.dot(X[:,train])-b)==Y[train])/sp.double(train.shape[0])\n",
    "\t\tacc_test[ifold] = sp.sum(sp.sign(w.dot(X[:,test])-b)==Y[test])/sp.double(test.shape[0])\n",
    "\t\n",
    "\treturn acc_train,acc_test\n",
    "\t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
